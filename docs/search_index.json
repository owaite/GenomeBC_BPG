[["index.html", "Guidelines and Procedures for Drone Based Phenotyping in Forest Research Trials Guidelines and Procedures for Drone Based Phenotyping in Forest Research Trials GitHub link Acknowledgements How to cite this report:", " Guidelines and Procedures for Drone Based Phenotyping in Forest Research Trials Jake King*, Olivia Waite, Miriam Isaac-Renton, Nicholas C. Coops, Samuel Grubinger, Liam Irwin, Lise Van Der Merwe, Jon Degner, Alex Liu Guidelines and Procedures for Drone Based Phenotyping in Forest Research Trials Date last updated: 2024-07-08 “Jake King1, Olivia Waite1, Alex Liu1, Miriam Isaac-Renton1, Nicholas C. Coops2, Samuel Grubinger2, Liam Irwin2, Lise Van Der Merwe3, Jon Degner3, Alvin Yanchuk3” 1 Natural Resources Canada, Canadian Forest Services, Canadian Wood Fibre Center, 506 Burnside Road West, Victoria, British Columbia, V8Z 1MZ. 2 Integrated Remote Sensing Studio, Faculty of Forestry, University of British Columbia,2424 Main Mall, Vancouver, BC V6T 1Z4, Canada. 3 BC Ministry of Forests, Cowichan Lake Research Station, 7060 Forestry Rd, Mesachie Lake, BC V0R 2N0. GitHub link Below is the link to the GitHub where you can access full scripts referenced in this document GitHub Link: PARSER-GBC-GitHub Acknowledgements These guidelines were made possible thanks for project funding from Genome British Columbia’s GeneSolve program, the Canadian Forest Service’s Fibre Solutions, 2 Billion Tree programs, and Assistant Deputy Minister’s Innovation Fund. For administrative assistance, we thank Adam Dick, Olivier van Lier, Marlene Francis, Annick Pelletier, Lise Carron, Guy Smith and Amélie Roberge. For practical input, we thank Bill Lakeland, Alec Wilson, Eric Saczuk, Keenan Rudichuk and David Huntley. How to cite this report: "],["glossary.html", "Glossary", " Glossary "],["contents.html", "Contents", " Contents "],["background-and-basis-of-knowledge.html", "Chapter 1 Background and basis of knowledge", " Chapter 1 Background and basis of knowledge "],["standard-operating-procedures-for-dji-m300-mapping-flights.html", "Chapter 2 Standard Operating Procedures for DJI M300 Mapping Flights", " Chapter 2 Standard Operating Procedures for DJI M300 Mapping Flights Overview: This is for DJI M300 mapping flights above forestry research trials and does not extend to flying within 30m of bystanders or over buildings. All relevant Transport Canada drone regulations will be adhered to. Emergency procedures: "],["overview-of-methodologies.html", "Chapter 3 Overview of Methodologies", " Chapter 3 Overview of Methodologies "],["range-of-sites-assessed.html", "Chapter 4 Range of Sites Assessed", " Chapter 4 Range of Sites Assessed "],["preflight-planning.html", "Chapter 5 Preflight Planning 5.1 Aligning and registering data from different time points and sensors 5.2 Site Selection Considerations", " Chapter 5 Preflight Planning hello 5.1 Aligning and registering data from different time points and sensors hello 5.1.1 Kinematic processing: RTK/PPK hello 5.1.2 Ground Control Points (GCPs) hello 5.1.3 Absolute and Relative Reference with Precise Point Positioning hello 5.1.4 Terrain Following on Sites with Elevation Gain hello 5.2 Site Selection Considerations hello "],["lidar-processing-workflow.html", "Chapter 6 LiDAR Processing Workflow 6.1 DJI Terra 6.2 Register the LiDAR to the DAP point cloud 6.3 Normalization and individual tree point clouds 6.4 Individual Tree Metrics", " Chapter 6 LiDAR Processing Workflow 6.1 DJI Terra Open DJI Terra and start a LiDAR Point Cloud Processing session Import the flight files, including imagery if you would like a colorized point cloud Below are the settings we use to process the point cloud: We use the deafult settings set by DJI with the exception of setting the DEM resolution to 10cm 6.2 Register the LiDAR to the DAP point cloud Convention is generally to register DAP to LiDAR however for this specific project it made more sense to register the LiDAR to the DAP because: - We were flying biweekly multispectral and RGB imagery and only 2-3 LiDAR acquisitions a year. - We could not load the LiDAR point cloud into Agisoft Metashape to use as a reference for registration however could register all DAP clouds to a reference DAP cloud in Agisoft. - This allowed us to more easily register the many multispectral and RGB acquisitions to a defined template in Agisoft Metashape and use the exported point cloud of the template DAP to register the LiDAR in CloudCompare. - This process worked well for us since our priority was centimeter-level registration of orthomosaics and LiDAR between many dates and across multiple sensors. 6.2.1 Prepare LiDAR for registration Below are snipets of a script written in LAStools that is used to ensure the LiDAR and DAP clouds are in the proper projection, filters out points in the LiDAR that are above a defined threshold, and clips the LiDAR to a boundary polygon to speed up registration by avoiding working with excess data in CloudCompare. The unparsed script can be found on the project GitHub, see GitHub link Ensures both the DAP point cloud and LiDAR file are in the proper projection (NAD83 UTM 10N in our case) path_to_L1_las is the path to the LiDAR .las file from DJI terra. path_to_write is where the path the projected .laz file will be written to. The files will be saved out with the same file name as the origianl LiDAR file with a “_nad83” suffix. “REM” works to comment out a line in LAStools as “#” does in R. REM Project DAP and save out as a .laz las2las -i path_to_DAP_las_file ^ -odir path_to_write ^ -odix _nad83 ^ -olaz ^ -nad83 ^ -utm 10north ^ -cpu64 ^ -v REM Project LiDAR and save out as a .laz las2las -i path_to_L1_las ^ -odir path_to_write ^ -odix _nad83 ^ -olaz ^ -nad83 ^ -utm 10north ^ -cpu64 ^ -v Drops points in the LiDAR point cloud above a user defined threshold to remove noisy points that are not from the canopy (i.e. due to air moisture, birds, etc.). To determine this height threshold you can plot a histogram of Z values or visualize the point cloud in a software that allows 3D point cloud visualization to ensure that the threshold will not result in any top canopy points being removed. Though we use CloudCompare for point cloud registration, we recommend Potree to visualize point clouds as it handles large point clouds quickly and with ease. Both Potree and CloudCompare are open-source software. If you do not have any point above the canopy or below the ground that need removing you can skip this step. path_to_projected_L1 is the path to the projected LiDAR .laz file from above REM dropping points above 160m (160m is the height cutoff for this dataset) las2las -i path_to_projected_L1 ^ -odir path_to_write ^ -odix _droppedPtsAbove160m ^ -olaz ^ -drop_z_above 160 ^ -cpu64 ^ -v Lastly we clip the LiDAR file to a boundary polygon of the site to remove excess surrounding data that can slow processing in CloudCompare. path_to_shp is the path to the site shapefile. path_to_projected_below160m_L1 is the path to .laz file that has been projected and filtered for points above a set threshold in steps 1 and 2 above. “-odix _clipped” will save the new laz file with the same name as the input file with “_clipped” attached to the end, change the “_clipped” to work with your naming system. lasclip -i path_to_projected_below160m_L1 -merged -path_to_shp -odir path_to_write -odix _clipped -olaz 6.2.2 Register LiDAR to DAP cloud in CloudCompare Import both the LiDAR and DAP clouds into CloudCompare (CC). This can take up to twenty minutes. Allow all for the first two warnings. 6.2.2.1 Examine the point clouds for artifacts. The L1 will reflect flight lines when there is moisture in the air. Below is an example point cloud from a damp day on the coast just after a fog past through. For sake of the example, it was not filtered in LAStools with a height threshold. The residual fog patches seen above the canopy can be clipped out using the cross section or segment tool. ** IMAGE of TOOLS MENTIONED ** ****************************************** 6.2.2.2 Rough Alignment The goal is to roughly align (move) the LiDAR to our reference “template” DAP dense cloud ahead of the ICP fine adjustment algorithm. Problem: Manually moving the LiDAR cloud to roughly align with the DAP cloud caused Cloud Compare to crash or hang when working with larger data sets. Solution: Use the Apply Transformation function in CloudCompare – Highlight the LiDAR layer in the DB tree - Hit ctrl T or Apply Transformation in the Edit menu. In this example the LiDAR is the lower. First apply a Z transformation. It is best to do this while viewing the edge of the plot. Here we applied a Z transformation of +6. Next Apply transformations in the x and y axis. Find a section of the clouds where you can easily see the alignment. In this case there is a single large leave tree in the centre of the plot. The LiDAR is the one on the left. Here we see the LiDAR is offset to the left (negative) on the Y(green) axis and up (positive) on the x(red) axis. Be careful not to rotate, only transform. In this case the LiDAR was shifted -5 in the X and +5 in the Y axis in total. The shift was done in three smaller iterations to achieve the alignment seen in the above screen capture. 6.2.2.3 Fine Registration: Iterative Closest Point (ICP) Highlight both clouds in the DB tree and apply the fine registration (ICP) algorithm using the following settings. Careful to set a max thread count that matches the resources you have available. Save out the registered LiDAR point clouda at the highest resolution 6.2.3 Rescale and tile the registered LiDAR: Below are snipets of a script written in LAStools that is used to proeject, rescale and tile the registered LiDAR point cloud. The unparsed script can be found on the project GitHub, see GitHub link Projecting the registered LiDAR to the proper projection (NAD83 UTM 10N). If you are working with already tiled data or multiple .laz/.las files on a multi-core computer than you can use the cores command shown below. Here we defined cores=4 which allows 4 cores to work on the command simultaneously on different files. If you are only working with one .laz/.las file at this point there is no need to specify the number of cores and the “^ -cores %cores%” following the “-v ^” should be removed from the below code Change “path_to_registered_lidar” to the path to the registered LiDAR data exported from CloudCompare. “*.las” takes the las file in that folder, change to the file name if have more than one .las in the folder and you want to specify a specific file. Change “path_to_write\\01_proj_NAD83” to the path you would like the new projected .laz file to be written to. set cores=4 las2las -i path_to_registered_lidar\\*.las ^ -odir path_to_write\\01_proj_NAD83 ^ -odix _nad83 ^ -olaz ^ -nad83 ^ -utm 10north ^ -cpu64 ^ -v ^ -cores %cores% Rescales the data which is necessary to later load into R for normalization and metric calculations. Registered LiDAR is exported from CloudCompare at the highest resolution which changes the scale of the data, hence rescaling the x,y,z to 0.01 is necessary to avoid warnings/errors in R “path_to_write” is in the input dir and the output dir because its the main folder we are now working in “path_to_write\\01_proj_NAD83*.laz” selects the .laz file in the “path_to_write\\01_proj_NAD83” folder, if there are more than one .laz file in your folder and you want to specify which to call, change the “*” to the name of the file. The output .laz file will be written to the “path_to_write\\02_rescaled” folder with the same name as the original file. las2las -i path_to_write\\01_proj_NAD83\\*.laz ^ -rescale 0.01 0.01 0.01 ^ -cpu64 ^ -utm 10north ^ -v ^ -odir path_to_write\\02_rescaled ^ -olaz Next the code indexes the LiDAR data. Indexing creates a “.lax” file for a given .las or .laz file that contains spatial indexing information. When this LAX file is present it will be used to speed up access to the relevant areas of the LAS/LAZ file for spatial queries. REM Indexing lasindex -i path_to_write\\02_rescaled\\*.laz Lastly tiling divides the point clouds into tiles to allow for parallel processing in the following R steps. “tile_size 15” sets the size of the tiles to 15m. “buffer 4” sets the size of the buffer surrounding the tiles to 4m. “flag_as_withheld” flags the buffer points so that they can be easily filtered out in the following steps in R. REM Creating 15m tiles lastile -i path_to_write\\02_rescaled\\*.laz ^ -tile_size 15 ^ -buffer 4 ^ -flag_as_withheld ^ -odir path_to_write\\03_tile ^ -olaz 6.3 Normalization and individual tree point clouds The below workflow includes explanations and code where applicable for each of the following: 1. Creating a 10cm DTM from the registered LiDAR tiles 2. Normalizing the tiles using the DTM 3. Creating a 4cm CHM from the max Z values in each pixel 4. Segmenting the tiles to only retain the top 25% of each tree using the crown polygons. The threshold will be site and age dependent. We set our threshold to the top 25% given that the trees were mature with crown closure and we were not confident the lower 75% of the point cloud did not contain any invading neighboring branches. 5. Merging segmented tiles to create one large point cloud containing the top 25% of each tree 6. Clipping the point cloud into individual point clouds per tree Note: The full code that can be found on the project GitHub runs through the above steps in a for loop. For sake of this guide we have rearranged the ordering of some steps (i.e. functions will be defined as we go in this guide, however are defined at the beginning in the full R script to allow the for loop to run). 6.3.1 Creating a DTM from the registered LiDAR tiles To being, when working with LiDAR data in R, an incredibly useful package is the lidR package. We highly recommend taking a look at the lidR bookdown for useful tips and examples on using the package. The packages required for our workflow are: library(tidyverse) library(sf) library(sp) library(spatial) library(raster) # working with raster data library(terra) library(lidR) # reading and processing LiDAR data library(sp) # defines and allows us to work with spatial objects library(nngeo) library(future) library(rmapshaper) library(concaveman) library(parallel) library(foreach) library(smoothr) library(ForestTools) library(gdalUtilities) library(exactextractr) library(alphashape3d) # Creates alpha shapes used to calculate crown volume library(lwgeom) library(dplyr) Here we are reading in the output tiles from the tiling and rescaling step above. We then drop the buffer points that were flagged as withheld in the LAStools tiling stage, set the new chunk buffer to 0.5m and set the opt_output_files to empty given that we do not want to save DTMs for the individual tiles but rather one for the entire site. dir &lt;- &quot;set_path_to_folders&quot; TILES = readLAScatalog(folder = paste0(dir, &quot;\\\\03_tile\\\\&quot;), filter = &quot;drop_withheld&quot;) opt_filter(TILES) &lt;- &quot;-drop_withheld&quot; # set filtering options for the LAScatalog object to drop withheld points opt_chunk_buffer(TILES) = .5 # set the buffer size for chunks in the LAScatalog object to 0.5m opt_laz_compression(TILES) = TRUE # enable LAZ compression for the LAScatalog object opt_output_files(TILES) = &quot;&quot; # set output file options for the LAScatalog object to empty opt_progress(TILES) = TRUE # enable progress tracking for processing Next we create a 10cm DTM using the tin() algorithm and smooth the raster by using the mean focal statistic and a focal window of 25m by 25m over the DTM. As the focal window shifts over the raster, it updates the pixel that sits at its center to the mean value within the 25m by 25m window. We then assigned the proper CRS and exported the raster as a tif. # Create a DTM DTM = grid_terrain(TILES, res = 0.1, tin(), full_raster = FALSE) %&gt;% # applying a focal operation to the DTM raster. # computing the mean value within a moving window defined by a matrix. focal(w = matrix(1, 25, 25), # define a 25x25 window with all values as 1 fun = mean, # use the mean function to compute the focal statistic na.rm = TRUE, # remove NA values from computation pad = TRUE) # pad the edges of the raster with NAs to maintain the original extent crs(DTM) &lt;- CRS(&quot;+proj=utm +zone=10 +datum=NAD83&quot;) # assign a CRS to the raster using the proj4 string representation writeRaster(DTM, paste0(dir, &quot;\\\\04_RASTER\\\\&quot;, site, &quot;_DTM_0.1m.tif&quot;), overwrite = TRUE) #save the DTM 6.3.2 Normalizing the tiles using the DTM 6.3.3 Creating a 4cm CHM from the max Z values in each pixel 6.3.4 Segmenting the tiles to only retain the top 25% of each tree using the crown polygons. The threshold will be site and age dependent. We set our threshold to the top 25% given that the trees were mature with crown closure and we were not confident the lower 75% of the point cloud did not contain any invading neighboring branches. 6.3.5 Merging segmented tiles to create one large point cloud containing the top 25% of each tree 6.3.6 Clipping the point cloud into individual point clouds per tree 6.4 Individual Tree Metrics Calculates metrics on indiviual tree point clouds: Height percentiles: 99, 97.5, 95, 92.5, mean height Volumes: Convex, concave, volume from an alpha shape of 0.5 Crown complexity: rumple, canopy rugosity ratio, coefficient of variation of height . "],["crown-segmentation.html", "Chapter 7 Crown segmentation", " Chapter 7 Crown segmentation We are using supercells to create segmentated crowns using: - A shapefile (.shp) with a grid of tree locations derived by georeferencing the census data to the imagery. This will be referred to as the “grid”. - Co-registered CHM made from normalized maximum elevation (Z) values, MicaSense orthomosaic, and P1 orthomosaic, ideally from the same date Creates a 2D .shp file representing the location of each tree from a csv of census data including row and col data per tree. This .shp will be refered to as the grid Usisng the CHM, finds treetops and snaps each tree in the grid to a treetop found within a 40cm radius Check the location of the treetops to the P1 orthomosaic and manual move treetops to align with trees in the P1 orthomosaic where necessary. Load in manually edited treetops, create circles proportional to tree height. Create a segmentation raster using the CHM and MicaSense and P1 orthomosaics Filter out segments that do not touch any of the circles proportional to tree height Merge remaining segments to create crown polygons Load into a GIS, along with the edited treetops and P1 orthhtomosaic, and edit the crown polygons to remove sections where neighbouring branches intersect the crown to ensure the crowns contain only data from the correct tree "]]
